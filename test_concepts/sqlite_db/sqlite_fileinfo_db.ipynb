{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo for synchronization of two data directories\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import farmhash\n",
    "import time\n",
    "import sqlite3\n",
    "import json\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missions_readable = {   \"clem1-l-spice-6-v1.0\"       : \"clementine\",\n",
    "                        \"co-s_j_e_v-spice-6-v1.0\"    : \"cassini_orbiter\",\n",
    "                        \"dawn-m_a-spice-6-v1.0\"      : \"dawn\",\n",
    "                        \"di-c-spice-6-v1.0\"          : \"deep_impact\",\n",
    "                        \"dif-c_e_x-spice-6-v1.0\"     : \"epoxi\",\n",
    "                        \"ds1-a_c-spice-6-v1.0\"       : \"deep_space_1\",\n",
    "                        \"grail-l-spice-6-v1.0\"       : \"grail\",\n",
    "                        \"hay-a-spice-6-v1.0\"         : \"hayabusa\",\n",
    "                        \"jno-j_e_ss-spice-6-v1.0\"    : \"juno\",\n",
    "                        \"lro-l-spice-6-v1.0\"         : \"lunar_reconnaissance_orbiter\",\n",
    "                        \"mer1-m-spice-6-v1.0\"        : \"mer_1\",\n",
    "                        \"mer2-m-spice-6-v1.0\"        : \"mer_2\",\n",
    "                        \"mess-e_v_h-spice-6-v1.0\"    : \"messenger\",\n",
    "                        \"mex-e_m-spice-6-v1.0\"       : \"mars_express\",\n",
    "                        \"mgs-m-spice-6-v1.0\"         : \"mars_global_surveyor\",\n",
    "                        \"mro-m-spice-6-v1.0\"         : \"mars_reconnaissance_orbiter\",\n",
    "                        \"msl-m-spice-6-v1.0\"         : \"mars_science_laboratory\",\n",
    "                        \"near-a-spice-6-v1.0\"        : \"near\",\n",
    "                        \"nh-j_p_ss-spice-6-v1.0\"     : \"new_horizons\",\n",
    "                        \"ody-m-spice-6-v1.0\"         : \"mars_odyssey\",\n",
    "                        \"ros-e_m_a_c-spice-6-v1.0\"   : \"rosetta\",\n",
    "                        \"sdu-c-spice-6-v1.0\"         : \"stardust\",\n",
    "                        \"vco-v-spice-6-v1.0\"         : \"venus_climate_orbiter\",\n",
    "                        \"vex-e_v-spice-6-v1.0\"       : \"venus_express\",\n",
    "                        \"vo1_vo2-m-spice-6-v1.0\"     : \"viking_orbiter\"}\n",
    "\n",
    "missions_true = {value: key for key, value in missions_readable.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirdf(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"Error: Directory '\" + directory + \"' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    filenames = []\n",
    "    hashvalues = []\n",
    "    \n",
    "    for root, subdir, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if not name[0] == \".\": # ignore hidden files\n",
    "                filepath = os.path.join(root, name)\n",
    "                \n",
    "                # hash full file contents\n",
    "                # note: spice data encoding is mixed, so read as binary\n",
    "                file = str(io.open(filepath,'rb').read()) \n",
    "                filenames.append(filepath.split(directory, 1)[1])\n",
    "                hashvalues.append(farmhash.hash64(file))\n",
    "                \n",
    "    df = pd.DataFrame(data=hashvalues, index = filenames, columns = [\"Hash\"])\n",
    "    df.index.name = directory\n",
    "    return df\n",
    "\n",
    "start = time.time()\n",
    "dir1df = create_dirdf(\"/Users/thatcher/Desktop/Classes/Capstone/SpiceData/\")\n",
    "print(\"elapsed time: \", time.time() - start)\n",
    "print(dir1df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newest_mk(path):\n",
    "    files = glob.glob(path + '*.tm')\n",
    "    metakernels = []\n",
    "    sorted_mk = {}\n",
    "    newest_mk = []\n",
    "    \n",
    "    for f in files:\n",
    "        meta = f.split('mk/')\n",
    "        metakernels.append(meta[1])\n",
    "\n",
    "    for mk in metakernels:\n",
    "        version = re.search('v[0-9]+', mk)\n",
    "        version1 = re.search('([^;]*)_([^;]*)_', mk)\n",
    "        newest_mk.append(version.group(0))\n",
    "        sorted_mk[version1.group(0)] = version.group(0)\n",
    "    \n",
    "    return sorted_mk\n",
    "\n",
    "def newest_kernel(path):\n",
    "    all_files = glob.glob(path + '/**/' + '*.*', recursive=True)\n",
    "    files = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        \n",
    "        if file.endswith('.lbl') or file.endswith('.txt'):\n",
    "            continue\n",
    "        else:\n",
    "            files.append(file)\n",
    "            \n",
    "    metakernels = []\n",
    "    newest_mk = []\n",
    "    sorted_mk = {}\n",
    "    \n",
    "    for f in files:\n",
    "        kern = f.split('data')\n",
    "        metakernels.append(kern[1])\n",
    "            \n",
    "    for mk in metakernels:\n",
    "#         version = re.search('v[0-9]+\\.', mk)\n",
    "        version1 = re.search('v[0-9]+', mk)\n",
    "        version2 = re.search('_v[0-9]+', mk)\n",
    "\n",
    "        split = mk.split('.')\n",
    "\n",
    "        if version2:\n",
    "            split = mk.split('_v')\n",
    "\n",
    "        elif version1:\n",
    "            split = mk.split('v')\n",
    "            \n",
    "        sorted_mk[split[0]] = mk\n",
    "            \n",
    "#         if version1 == None:\n",
    "#             sorted_mk[mk] = 'Newest'\n",
    "#         else:\n",
    "#             sorted_mk[version1.group(0).split('v')[0]] = mk\n",
    "#             print(mk)\n",
    "\n",
    "\n",
    "    return sorted_mk\n",
    "\n",
    "files = newest_kernel('/Users/thatcher/Desktop/Classes/Capstone/SpiceData/mess-e_v_h-spice-6-v1.0/messsp_1000/data')\n",
    "\n",
    "for file in files:\n",
    "    print('File: ' + file + ' Val:' + files[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spicedb(spdir):\n",
    "    \n",
    "    if os.path.exists('./spicedb.sqlite'):\n",
    "        os.remove('./spicedb.sqlite')\n",
    "        \n",
    "    if not os.path.exists(spdir):\n",
    "        print(\"Error: Directory '\" + spdir + \"' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    kern_dict = newest_kernel('/Users/thatcher/Desktop/Classes/Capstone/SpiceData/clem1-l-spice-6-v1.0/clsp_1000/data/')\n",
    "    conn = sqlite3.connect('./spicedb.sqlite') # initialize db, this might move to an init func in the api\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(\"CREATE TABLE SPICE (Mission TEXT)\") # create missions table\n",
    "    c.execute(\"ALTER TABLE SPICE ADD COLUMN Kernel TEXT\")\n",
    "    c.execute(\"ALTER TABLE SPICE ADD COLUMN File TEXT\")\n",
    "    c.execute(\"ALTER TABLE SPICE ADD COLUMN Path TEXT\")\n",
    "    c.execute(\"ALTER TABLE SPICE ADD COLUMN Hash TEXT\") #theres probs a way to to this in one line\n",
    "    c.execute(\"ALTER TABLE SPICE ADD COLUMN Newest TEXT\")\n",
    "\n",
    "    # ooh spicy tabs ~ we could probably just parse first two directories from full string?????\n",
    "    for mis in [m for m in os.listdir(spdir) if not m[0] == '.']:\n",
    "        for ker in [k for k in os.listdir(spdir+'/'+mis) if not k[0] == '.']:\n",
    "             for root, subdir, files in os.walk(spdir+'/'+mis+'/'+ker):\n",
    "                for name in files:\n",
    "                    if not name[0] == \".\": # ignore hidden files\n",
    "                        print(name)\n",
    "                        filepath = os.getcwd()\n",
    "                        \n",
    "                        if name in kern_dict:\n",
    "                            newest = kern_dict[name]\n",
    "                            \n",
    "                        else:\n",
    "                            newest = 'Newest'\n",
    "                            \n",
    "                        mis_hr = missions_readable[mis]\n",
    "                        fhash = farmhash.hash64(str(io.open(os.path.join(root, name),'rb').read())) # spice data encoding is mixed, so read as binary\n",
    "                        c.execute(\"INSERT OR IGNORE INTO SPICE (Mission, Kernel, File, Path, Hash, Newest) VALUES ('{mn}', '{kn}', '{fn}', '{fp}', '{fh}', '{new}')\"\n",
    "                                  .format(mn=mis_hr, kn=root.split('/')[-1], fn=name, fp=filepath, fh=fhash, new=newest))\n",
    "    conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_spicedb('/Users/thatcher/Desktop/Classes/Capstone/SpiceData/')\n",
    "conn = sqlite3.connect('./spicedb.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT * FROM SPICE WHERE Kernel != 'Newest'\")\n",
    "# Note: fetchall() will pull the whole buffer, if you SELECT ten times, the result will be in there ten times\n",
    "all_rows = c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in all_rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary of a single row from a sql select return\n",
    "def sql_dict(sql_row):\n",
    "    return { 'mission': sql_row[0],\n",
    "             'kernel' : sql_row[1],\n",
    "             'file'   : sql_row[2],\n",
    "             'path'   : sql_row[3],\n",
    "             'hash'   : sql_row[4],\n",
    "             'newest' : sql_row[5] }\n",
    "\n",
    "# returns an array of dictionaries of a whole sql select return\n",
    "def sql_dict_array(sql_rows):\n",
    "    dicts = []\n",
    "    for row in sql_rows:\n",
    "        dicts.append(sql_dict(row))\n",
    "    return dicts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_output = sql_dict_array(all_rows)\n",
    "for d in select_output:\n",
    "    print(json.dumps(d, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
